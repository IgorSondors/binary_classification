{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/sondors/Documents/price/ColBERT\")\n",
    "\n",
    "from interface import load_model#, get_query_emb_batch\n",
    "from typing import List, Dict\n",
    "from colbert.modeling.checkpoint import Checkpoint\n",
    "\n",
    "import wandb\n",
    "\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim=(32, 768), latent_dim=128):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim[0] * input_dim[1], 1024)  # Flatten input\n",
    "        self.fc2 = nn.Linear(1024, 256)\n",
    "        self.fc31 = nn.Linear(256, latent_dim)\n",
    "        self.fc32 = nn.Linear(256, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten the matrix to a vector\n",
    "        h = F.relu(self.fc1(x))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        return self.fc31(h), self.fc32(h)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=128, output_dim=(32, 768)):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(latent_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 1024)\n",
    "        self.fc3 = nn.Linear(1024, output_dim[0] * output_dim[1])\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def forward(self, z):\n",
    "        h = F.relu(self.fc1(z))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        return torch.sigmoid(self.fc3(h)).view(-1, self.output_dim[0], self.output_dim[1])  # Reshape to original\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encoder(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        return self.decoder(z), mu, log_var\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(latent_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, z1, z2):\n",
    "        h1 = F.relu(self.fc1(z1))\n",
    "        h2 = F.relu(self.fc1(z2))\n",
    "        diff = torch.abs(h1 - h2)\n",
    "        out = self.fc2(diff)\n",
    "        return self.fc3(out).squeeze(1)  # Ensure this line produces a shape of [batch_size]\n",
    "\n",
    "def get_query_emb(sentences: List[str], checkpoint: Checkpoint, batch_size: int) -> torch.Tensor:\n",
    "    with torch.no_grad():\n",
    "        return checkpoint.queryFromText(sentences, bsize=batch_size)#.to(\"cpu\").numpy()\n",
    "\n",
    "def get_query_emb_batch(sentences: List[str], checkpoint: Checkpoint, batch_size: int, batch_size2: int) -> torch.Tensor:\n",
    "    embeddings_list = []\n",
    "    \n",
    "    for i in range(0, len(sentences), batch_size2):\n",
    "        batch_sentences = sentences[i:i+batch_size2]\n",
    "        with torch.no_grad():\n",
    "            embeddings = torch.tensor(get_query_emb(batch_sentences, checkpoint, batch_size), dtype=torch.float32)\n",
    "        embeddings_list.append(embeddings)\n",
    "    \n",
    "    combined_embeddings = torch.cat(embeddings_list, dim=0)\n",
    "    return combined_embeddings\n",
    "\n",
    "def vae_loss(recon_x, x, mu, log_var):\n",
    "    BCE = F.binary_cross_entropy_with_logits(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return BCE + KLD\n",
    "def save_model(vae, siamese, optimizer, epoch, path='./models'):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'vae_state_dict': vae.state_dict(),\n",
    "        'siamese_state_dict': siamese.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, os.path.join(path, f'checkpoint_epoch_{epoch}.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ckpt_pth = \"/home/sondors/Documents/ColBERT_weights/2801_lr04_bsize_210_apple/none/2024-04/18/09.16.10/checkpoints/colbert-187-finish\"\n",
    "experiment = \"colbert-187-finish\"\n",
    "\n",
    "doc_maxlen = 300\n",
    "nbits = 2\n",
    "nranks = 1\n",
    "kmeans_niters = 4\n",
    "\n",
    "device = \"cuda\"\n",
    "checkpoint = load_model(ckpt_pth, doc_maxlen, nbits, kmeans_niters, device)\n",
    "\n",
    "pth_models = \"/home/sondors/Documents/price/BERT_data/data/17-04-2024_Timofey/2801_offers_models_Apple.csv\"\n",
    "pth_offers = '/home/sondors/Documents/price/BERT_data/data/17-04-2024_Timofey/2801_Apple_triplets_offer_model_train.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер тренировочной выборки: 850\n",
      "Размер тестовой выборки: 150\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, offers: List[str], true_matches: List[str], false_matches: List[str], checkpoint: Checkpoint, batch_size: int, batch_size2: int):\n",
    "        self.offers = offers\n",
    "        self.true_matches = true_matches\n",
    "        self.false_matches = false_matches\n",
    "        self.checkpoint = checkpoint\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_size2 = batch_size2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.offers)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        offer_embs = get_query_emb_batch([self.offers[idx]], self.checkpoint, batch_size=self.batch_size, batch_size2=self.batch_size2)\n",
    "        true_match_embs = get_query_emb_batch([self.true_matches[idx]], self.checkpoint, batch_size=self.batch_size, batch_size2=self.batch_size2)\n",
    "        false_match_embs = get_query_emb_batch([self.false_matches[idx]], self.checkpoint, batch_size=self.batch_size, batch_size2=self.batch_size2)\n",
    "\n",
    "        y_true = torch.ones(len(true_match_embs))\n",
    "        y_false = torch.zeros(len(false_match_embs))\n",
    "\n",
    "        X = torch.cat([offer_embs, offer_embs], dim=0)\n",
    "        X_pair = torch.cat([true_match_embs, false_match_embs], dim=0)\n",
    "        y = torch.cat([y_true, y_false], dim=0)\n",
    "\n",
    "        return X, X_pair, y\n",
    "    \n",
    "def load_data(pth_models, pth_offers, checkpoint, batch_size, batch_size2):\n",
    "    id_category = {\n",
    "        2801: 'мобильные телефоны'\n",
    "    }\n",
    "    \n",
    "    df_models = pd.read_csv(pth_models, sep=';')\n",
    "    df_offers = pd.read_csv(pth_offers, sep=';')\n",
    "    df_offers = df_offers[:1000]\n",
    "\n",
    "    df_models = df_models[df_models['category_id'].isin(id_category.keys())].reset_index(drop=True)\n",
    "    df_offers = df_offers[df_offers['category_id'].isin(id_category.keys())].reset_index(drop=True)\n",
    "\n",
    "    df_offers_shuffled = df_offers.sample(frac=1, random_state=42)\n",
    "\n",
    "    test_size = int(0.15 * len(df_offers_shuffled))\n",
    "\n",
    "    df_train = df_offers_shuffled.iloc[:-test_size]\n",
    "    df_test = df_offers_shuffled.iloc[-test_size:]\n",
    "\n",
    "    print(\"Размер тренировочной выборки:\", len(df_train))\n",
    "    print(\"Размер тестовой выборки:\", len(df_test))\n",
    "\n",
    "    offer_batch = list(df_train['name'])\n",
    "    true_match_batch = list(df_train['true_match'])\n",
    "    false_match_batch = list(df_train['false_match'])\n",
    "    train_dataset = MyDataset(offer_batch, true_match_batch, false_match_batch, checkpoint, batch_size, batch_size2)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    offer_batch = list(df_test['name'])\n",
    "    true_match_batch = list(df_test['true_match'])\n",
    "    false_match_batch = list(df_test['false_match'])\n",
    "    test_dataset = MyDataset(offer_batch, true_match_batch, false_match_batch, checkpoint, batch_size, batch_size2)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    return train_dataloader, test_dataloader\n",
    "\n",
    "batch_size = 100\n",
    "batch_size2 = 100000#3000\n",
    "train_dataloader, test_dataloader = load_data(pth_models, pth_offers, checkpoint, batch_size, batch_size2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sondors/anaconda3/envs/torch_gpu/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vae = VAE().to(device)\n",
    "siamese = SiameseNetwork().to(device)\n",
    "\n",
    "\n",
    "epochs = 15\n",
    "initial_lr = 0.01\n",
    "n_batches = len(train_dataloader)\n",
    "\n",
    "params = list(vae.parameters()) + list(siamese.parameters())\n",
    "optimizer = AdamW(params, lr=initial_lr, eps=1e-8)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)  # Scheduler definition\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=epochs*n_batches)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "criterion = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def validate(vae, siamese, dataloader, device):\n",
    "    vae.eval()\n",
    "    siamese.eval()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    mean_vae_time = 0\n",
    "    mean_seamese_time = 0\n",
    "\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for f, g, similarity in dataloader:\n",
    "            f, g, similarity = f.to(device).reshape(-1, 32, 768), g.to(device).reshape(-1, 32, 768), similarity.to(device).reshape(-1)\n",
    "\n",
    "            recon_f, mu_f, log_var_f = vae(f)\n",
    "            recon_g, mu_g, log_var_g = vae(g)\n",
    "\n",
    "            vae_time_start = time.time()\n",
    "            loss_vae_f = vae_loss(recon_f, f, mu_f, log_var_f)\n",
    "            loss_vae_g = vae_loss(recon_g, g, mu_g, log_var_g)\n",
    "            mean_vae_time += time.time() - vae_time_start\n",
    "\n",
    "            siamese_time_start = time.time()\n",
    "            similarity_score = siamese(vae.reparameterize(mu_f, log_var_f), vae.reparameterize(mu_g, log_var_g))\n",
    "            mean_seamese_time += time.time() - siamese_time_start\n",
    "\n",
    "            loss_siamese = criterion(similarity_score, similarity.view(-1))\n",
    "\n",
    "            loss = loss_vae_f + loss_vae_g + loss_siamese\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            predicted_labels = (similarity_score > 0).float()\n",
    "            correct_predictions += (predicted_labels == similarity.view(-1)).sum().item()\n",
    "            total_samples += similarity.size(0)\n",
    "\n",
    "            all_predictions.extend(similarity_score.detach().cpu().numpy())\n",
    "            all_targets.extend(similarity.cpu().numpy())\n",
    "\n",
    "    average_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    roc_auc = roc_auc_score(all_targets, all_predictions)\n",
    "    mean_vae_time = mean_vae_time / total_samples\n",
    "    mean_seamese_time = mean_seamese_time / total_samples\n",
    "\n",
    "    return average_loss, accuracy, roc_auc, mean_vae_time, mean_seamese_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35919/4241943564.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = torch.tensor(get_query_emb(batch_sentences, checkpoint, batch_size), dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.shape(f) = torch.Size([100, 2, 32, 768])\n",
      "np.shape(g) = torch.Size([100, 2, 32, 768])\n",
      "np.shape(similarity) = torch.Size([100, 2])\n",
      "np.shape(f) = torch.Size([200, 32, 768])\n",
      "np.shape(g) = torch.Size([200, 32, 768])\n",
      "np.shape(similarity) = torch.Size([200])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "vae.train()\n",
    "siamese.train()\n",
    "total_train_loss = 0\n",
    "\n",
    "batch_time = time.time()\n",
    "for batch_index, (f, g, similarity) in enumerate(train_dataloader):\n",
    "    # print(f\"f = {f}\")\n",
    "    print(f\"np.shape(f) = {np.shape(f)}\")\n",
    "    # print(f\"g = {g}\")\n",
    "    print(f\"np.shape(g) = {np.shape(g)}\")\n",
    "    # print(f\"similarity = {similarity}\")\n",
    "    print(f\"np.shape(similarity) = {np.shape(similarity)}\")\n",
    "\n",
    "    f, g, similarity = f.to(device).reshape(-1, 32, 768), g.to(device).reshape(-1, 32, 768), similarity.to(device).reshape(-1)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    with torch.cuda.amp.autocast():\n",
    "        recon_f, mu_f, log_var_f = vae(f)\n",
    "        recon_g, mu_g, log_var_g = vae(g)\n",
    "\n",
    "        # print(f\"f = {f}\")\n",
    "        print(f\"np.shape(f) = {np.shape(f)}\")\n",
    "        # print(f\"g = {g}\")\n",
    "        print(f\"np.shape(g) = {np.shape(g)}\")\n",
    "        # print(f\"similarity = {similarity}\")\n",
    "        print(f\"np.shape(similarity) = {np.shape(similarity)}\")\n",
    "\n",
    "        loss_vae_f = vae_loss(recon_f, f, mu_f, log_var_f)\n",
    "        loss_vae_g = vae_loss(recon_g, g, mu_g, log_var_g)\n",
    "\n",
    "        similarity_score = siamese(vae.reparameterize(mu_f, log_var_f), vae.reparameterize(mu_g, log_var_g))\n",
    "        loss_siamese = criterion(similarity_score, similarity.view(-1))\n",
    "\n",
    "        total_loss = loss_vae_f + loss_vae_g + loss_siamese\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35919/4241943564.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = torch.tensor(get_query_emb(batch_sentences, checkpoint, batch_size), dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z1 shape (input): torch.Size([200, 32, 768])\n",
      "h1 shape: torch.Size([200, 32, 64])\n",
      "z2 shape (input): torch.Size([200, 32, 768])\n",
      "h2 shape: torch.Size([200, 32, 64])\n",
      "diff shape: torch.Size([200, 32, 64])\n",
      "out shape (after fc2): torch.Size([200, 32, 32])\n",
      "out shape (after fc3): torch.Size([200, 32, 1])\n",
      "out shape (final output): torch.Size([200, 32])\n",
      "np.shape(outputs) = torch.Size([200, 32])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">83</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">80 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>outputs = similarity_model(f, g)                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">81 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># print(f\"outputs = {outputs}\")</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"np.shape(outputs) = {</span>np.shape(outputs)<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>)                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>83 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>loss = criterion(outputs, similarity)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">84 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>loss.backward()                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">85 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>optimizer.step()                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">86 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">break</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/sondors/anaconda3/envs/torch_gpu/lib/python3.8/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">11</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">94</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1191 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1194 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1195 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/sondors/anaconda3/envs/torch_gpu/lib/python3.8/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">loss.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">619</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 616 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>(BCELoss, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>).<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>(weight, size_average, reduce, reduction)            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 617 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 618 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: Tensor, target: Tensor) -&gt; Tensor:                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 619 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> F.binary_cross_entropy(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, target, weight=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight, reduction=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 620 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 621 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 622 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">class</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; text-decoration: underline\">BCEWithLogitsLoss</span>(_Loss):                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/sondors/anaconda3/envs/torch_gpu/lib/python3.8/site-packages/torch/nn/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">functional.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3086</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">binary_cross_entropy</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3083 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3084 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>reduction_enum = _Reduction.get_enum(reduction)                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3085 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> target.size() != <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>.size():                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3086 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3087 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"Using a target size ({}) that is different to the input size ({}) is deprec</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3088 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"Please ensure they have the same size.\"</span>.format(target.size(), <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>.size())  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3089 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>Using a target size <span style=\"font-weight: bold\">(</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span><span style=\"font-weight: bold\">]))</span> that is different to the input size <span style=\"font-weight: bold\">(</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span><span style=\"font-weight: bold\">]))</span> is \n",
       "deprecated. Please ensure they have the same size.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m83\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m80 \u001b[0m\u001b[2m│   │   \u001b[0moutputs = similarity_model(f, g)                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m81 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# print(f\"outputs = {outputs}\")\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m82 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mnp.shape(outputs) = \u001b[0m\u001b[33m{\u001b[0mnp.shape(outputs)\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m83 \u001b[2m│   │   \u001b[0mloss = criterion(outputs, similarity)                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m84 \u001b[0m\u001b[2m│   │   \u001b[0mloss.backward()                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m85 \u001b[0m\u001b[2m│   │   \u001b[0moptimizer.step()                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m86 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mbreak\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/sondors/anaconda3/envs/torch_gpu/lib/python3.8/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m11\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m94\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1191 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1194 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1195 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/sondors/anaconda3/envs/torch_gpu/lib/python3.8/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mloss.py\u001b[0m:\u001b[94m619\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mforward\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 616 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96msuper\u001b[0m(BCELoss, \u001b[96mself\u001b[0m).\u001b[92m__init__\u001b[0m(weight, size_average, reduce, reduction)            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 617 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 618 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor, target: Tensor) -> Tensor:                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 619 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m F.binary_cross_entropy(\u001b[96minput\u001b[0m, target, weight=\u001b[96mself\u001b[0m.weight, reduction=\u001b[96mself\u001b[0m.  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 620 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 621 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 622 \u001b[0m\u001b[94mclass\u001b[0m \u001b[4;92mBCEWithLogitsLoss\u001b[0m(_Loss):                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/sondors/anaconda3/envs/torch_gpu/lib/python3.8/site-packages/torch/nn/\u001b[0m\u001b[1;33mfunctional.py\u001b[0m:\u001b[94m3086\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mbinary_cross_entropy\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3083 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3084 \u001b[0m\u001b[2m│   │   \u001b[0mreduction_enum = _Reduction.get_enum(reduction)                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3085 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m target.size() != \u001b[96minput\u001b[0m.size():                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3086 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3087 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mUsing a target size (\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m) that is different to the input size (\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m) is deprec\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3088 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mPlease ensure they have the same size.\u001b[0m\u001b[33m\"\u001b[0m.format(target.size(), \u001b[96minput\u001b[0m.size())  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3089 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mValueError: \u001b[0mUsing a target size \u001b[1m(\u001b[0m\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m that is different to the input size \u001b[1m(\u001b[0m\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m200\u001b[0m, \u001b[1;36m32\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m is \n",
       "deprecated. Please ensure they have the same size.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# class SiameseNetwork(nn.Module):\n",
    "#     def __init__(self, latent_dim=768):\n",
    "#         super(SiameseNetwork, self).__init__()\n",
    "#         self.fc1 = nn.Linear(latent_dim, 64)\n",
    "#         self.fc2 = nn.Linear(64, 32)\n",
    "#         self.fc3 = nn.Linear(32, 1)\n",
    "#         self.fc4 = nn.Linear(32, 1)\n",
    "#         # self.fc3 = nn.Linear(1)\n",
    "\n",
    "#     def forward(self, z1, z2):\n",
    "#         h1 = F.relu(self.fc1(z1))\n",
    "#         h2 = F.relu(self.fc1(z2))\n",
    "#         diff = torch.abs(h1 - h2)\n",
    "#         token_by_token = self.fc2(diff)\n",
    "#         all_tokens_together = self.fc3(token_by_token.squeeze(1))\n",
    "#         # return out\n",
    "#         return self.fc4(all_tokens_together)#.squeeze(1)  # Ensure this line produces a shape of [batch_size]\n",
    "#         # return F.sigmoid(self.fc3(out).squeeze(1))  # Ensure this line produces a shape of [batch_size]\n",
    "    \n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, latent_dim=768):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(latent_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, z1, z2):\n",
    "        print(f\"z1 shape (input): {z1.shape}\")  # [batch_size, sequence_length, embedding_dim]\n",
    "        h1 = F.relu(self.fc1(z1))\n",
    "        print(f\"h1 shape: {h1.shape}\")  # [batch_size, sequence_length, 64]\n",
    "        \n",
    "        print(f\"z2 shape (input): {z2.shape}\")  # [batch_size, sequence_length, embedding_dim]\n",
    "        h2 = F.relu(self.fc1(z2))\n",
    "        print(f\"h2 shape: {h2.shape}\")  # [batch_size, sequence_length, 64]\n",
    "        \n",
    "        diff = torch.abs(h1 - h2)\n",
    "        print(f\"diff shape: {diff.shape}\")  # [batch_size, sequence_length, 64]\n",
    "        \n",
    "        out = F.relu(self.fc2(diff))\n",
    "        print(f\"out shape (after fc2): {out.shape}\")  # [batch_size, sequence_length, 32]\n",
    "        \n",
    "        out = self.fc3(out)\n",
    "        print(f\"out shape (after fc3): {out.shape}\")  # [batch_size, sequence_length, 1]\n",
    "        \n",
    "        out = out.squeeze(2)  # Squeeze the last dimension\n",
    "        print(f\"out shape (final output): {out.shape}\")  # [batch_size, sequence_length]\n",
    "        return out\n",
    "    \n",
    "# Инициализация модели, функции потерь и оптимизатора\n",
    "similarity_model = SiameseNetwork().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(similarity_model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# Обучающий цикл\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_index, (f, g, similarity) in enumerate(train_dataloader):\n",
    "        # print(f\"f = {f}\")\n",
    "        # print(f\"np.shape(f) = {np.shape(f)}\")\n",
    "        # # print(f\"g = {g}\")\n",
    "        # print(f\"np.shape(g) = {np.shape(g)}\")\n",
    "        # # print(f\"similarity = {similarity}\")\n",
    "        # print(f\"np.shape(similarity) = {np.shape(similarity)}\")\n",
    "\n",
    "        f, g, similarity = f.to(device).reshape(-1, 32, 768), g.to(device).reshape(-1, 32, 768), similarity.to(device).reshape(-1)\n",
    "        # print(f\"f = {f}\")\n",
    "        # print(f\"np.shape(f) = {np.shape(f)}\")\n",
    "        # # print(f\"g = {g}\")\n",
    "        # print(f\"np.shape(g) = {np.shape(g)}\")\n",
    "        # # print(f\"similarity = {similarity}\")\n",
    "        # print(f\"np.shape(similarity) = {np.shape(similarity)}\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = similarity_model(f, g)\n",
    "        # print(f\"outputs = {outputs}\")\n",
    "        print(f\"np.shape(outputs) = {np.shape(outputs)}\")\n",
    "        loss = criterion(outputs, similarity)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        break\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
